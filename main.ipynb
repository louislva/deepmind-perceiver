{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://data.deepai.org/mnist.zip -o mnist.zip\n",
    "!unzip mnist.zip -d mnist/\n",
    "!rm mnist.zip\n",
    "!gunzip mnist -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "device = 'cpu'\n",
    "\n",
    "def load_mnist_data(test=False):\n",
    "    if(test):\n",
    "        f_images = open('mnist/t10k-images-idx3-ubyte','rb')\n",
    "        f_labels = open('mnist/t10k-labels-idx1-ubyte','rb')\n",
    "    else:\n",
    "        f_images = open('mnist/train-images-idx3-ubyte','rb')\n",
    "        f_labels = open('mnist/train-labels-idx1-ubyte','rb')\n",
    "        \n",
    "    # skip bullshit start\n",
    "    f_images.seek(16)\n",
    "    f_labels.seek(8)\n",
    "    \n",
    "    # read whole file\n",
    "    buf_images = f_images.read()\n",
    "    buf_labels = f_labels.read()\n",
    "    \n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(-1, 1, 28, 28) / 256\n",
    "    \n",
    "    labels = np.frombuffer(buf_labels, dtype=np.uint8)\n",
    "    labels_one_hot = np.zeros((labels.shape[0], 10))\n",
    "    labels_one_hot[np.arange(labels.size), labels] = 1\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def sample_batch(X, Y, batch_size=32):\n",
    "    length = len(Y)\n",
    "    idx = np.random.choice(np.arange(0, length), size=(batch_size), replace=False)\n",
    "    \n",
    "    return X[idx], Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_board(d_model):\n",
    "    half = (d_model) // 2\n",
    "    texture = torch.cat([\n",
    "        torch.ones((half, 1)),\n",
    "        torch.zeros((half, 1))\n",
    "    ], dim=1).view((-1,))\n",
    "    \n",
    "    return texture\n",
    "\n",
    "def pos_embedding(x):\n",
    "        # x: (pos, n, i)\n",
    "        \n",
    "        length = x.shape[0]\n",
    "        batch_size = x.shape[1]\n",
    "        d_model = x.shape[2]\n",
    "\n",
    "        i = torch.arange(0, d_model).view((1, 1, -1)).expand(length, -1, d_model).to(device).float()\n",
    "        pos = torch.arange(0, length).view((-1, 1, 1)).expand(length, -1, d_model).to(device).float()\n",
    "        \n",
    "        z = pos / 10000 ** (i / d_model)\n",
    "        \n",
    "        sin = torch.sin(z)\n",
    "        cos = torch.cos(z)\n",
    "        \n",
    "        sin_mask = checker_board(d_model).to(device)\n",
    "        cos_mask = -sin_mask + 1\n",
    "                \n",
    "        pe = (sin_mask * sin) + (cos_mask * cos)\n",
    "        pe = pe.expand(length, batch_size, d_model)\n",
    "        \n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.25):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm([d_model])\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            d_model,\n",
    "            heads,\n",
    "            dropout=0.0,\n",
    "            bias=True,\n",
    "            add_bias_kv=True,\n",
    "        )\n",
    "        #self.dropout = nn.Dropout(p=dropout)\n",
    "        #self.linear1 = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        #self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.linear2 = nn.Linear(d_model, d_model)\n",
    "        #self.linear3 = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x, z_input):\n",
    "        x = self.layer_norm1(x)\n",
    "        z = self.layer_norm1(z_input)\n",
    "        z, _ = self.attention(z, x, x)\n",
    "        \n",
    "        #z = self.dropout(z)\n",
    "        #z = self.linear1(z)\n",
    "        \n",
    "        #z = self.layer_norm2(z)\n",
    "        z = self.linear2(z)\n",
    "        z = F.gelu(z)\n",
    "        #z = self.dropout(z)\n",
    "        #z = self.linear3(z)\n",
    "        \n",
    "        return z + z_input\n",
    "\n",
    "class PerceiverBlock(nn.Module):\n",
    "    def __init__(self, d_model, latent_blocks):\n",
    "        super(PerceiverBlock, self).__init__()\n",
    "        \n",
    "        self.cross_attention = AttentionBlock(d_model, heads=1)\n",
    "        self.latent_attentions = nn.ModuleList([\n",
    "            AttentionBlock(d_model, heads=4) for _ in range(latent_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        z = self.cross_attention(x, z)\n",
    "        #for latent_attention in self.latent_attentions:\n",
    "        #    z = latent_attention(z, z)\n",
    "        return z\n",
    "\n",
    "class Repeater(nn.Module):\n",
    "    def __init__(self, module, repeats=1):\n",
    "        super(Repeater, self).__init__()\n",
    "        \n",
    "        self.repeats = repeats\n",
    "        self.module = module\n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        for _ in range(self.repeats):\n",
    "            z = self.module(x, z)\n",
    "        return z\n",
    "    \n",
    "class Perceiver(nn.Module):\n",
    "    def __init__(self, output_size, latents=16, d_model=8, input_channels=1):\n",
    "        super(Perceiver, self).__init__()\n",
    "\n",
    "        self.init_latent = nn.Parameter(torch.rand((latents, d_model)))\n",
    "        self.embedding = nn.Conv1d(input_channels, d_model, 1)\n",
    "        \n",
    "        self.block1 = Repeater(PerceiverBlock(d_model, latent_blocks=2), repeats=1)\n",
    "        self.block2 = Repeater(PerceiverBlock(d_model, latent_blocks=2), repeats=2)\n",
    "        self.block3 = Repeater(PerceiverBlock(d_model, latent_blocks=2), repeats=2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, d_model)\n",
    "        self.linear2 = nn.Linear(d_model, output_size)   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transform our X (input)     \n",
    "        # x.shape = (batch_size, channels, width, height)\n",
    "        x = x.view((x.shape[0], x.shape[1], -1))\n",
    "        # x.shape = (batch_size, channels, pixels)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # x.shape = (batch_size, d_model, pixels)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        # x.shape (pixels, batch_size, d_model)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = pos_embedding(x)\n",
    "        \n",
    "        #imshow(x.detach().numpy() * 255)\n",
    "        \n",
    "               \n",
    "        #raise False\n",
    "               \n",
    "        # Transform our Z (latent)\n",
    "        # z.shape = (latents, d_model)\n",
    "        z = self.init_latent.unsqueeze(1)\n",
    "        # z.shape = (latents, 1, d_model)\n",
    "        z = z.expand(-1, x.shape[1], -1)\n",
    "        # z.shape = (latents, batch_size, d_model)\n",
    "        \n",
    "        #print('0', z)\n",
    "        z = self.block1(x, z)\n",
    "        #print('1', z)\n",
    "        z = self.block2(x, z)\n",
    "        z = self.block3(x, z)\n",
    "        #print('2', z)\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        z = z.mean(dim=0)\n",
    "        z = self.linear2(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "model = Perceiver(output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "        X_test, Y_test = load_mnist_data(test=True)\n",
    "        X_LENGTH = len(X_test)\n",
    "        BATCH_SIZE = 500\n",
    "        DEVICE = 'cpu'\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        t = range(X_LENGTH // BATCH_SIZE)\n",
    "        for i in t:\n",
    "            x = torch.from_numpy(X_test[i * BATCH_SIZE:(i+1) * BATCH_SIZE]).float().to(DEVICE)\n",
    "            y = torch.from_numpy(Y_test[i * BATCH_SIZE:(i+1) * BATCH_SIZE]).long().to(DEVICE)\n",
    "\n",
    "            y_ = model(x).argmax(dim=-1)\n",
    "\n",
    "            total += len(y_)\n",
    "            correct += (y_ == y).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "    \n",
    "def train(model, SKIP_EPOCHS=-1, EPOCHS=10, BATCH_SIZE=32, DEVICE='cpu'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1, last_epoch=-1, verbose=False)\n",
    "\n",
    "    X_train, Y_train = load_mnist_data(test=False)\n",
    "    X_LENGTH = len(X_train)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH', epoch, '[LEARNING RATE: ' + str(optimizer.param_groups[0]['lr']) + ']')\n",
    "        if(epoch <= SKIP_EPOCHS):\n",
    "            scheduler.step()\n",
    "            continue\n",
    "\n",
    "        t = trange(X_LENGTH // BATCH_SIZE)\n",
    "        for _ in t:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = sample_batch(X_train, Y_train, BATCH_SIZE)\n",
    "            x = torch.from_numpy(x).float().to(DEVICE)\n",
    "            y = torch.from_numpy(y).long().to(DEVICE)\n",
    "\n",
    "            y_ = model(x)\n",
    "            loss = nn.CrossEntropyLoss()(y_, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(str(loss.item())[0:5])\n",
    "        print('[ACCURACY: ' + str(test(model)) + ']')\n",
    "        scheduler.step()\n",
    "        \n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "imshow(data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
