{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://data.deepai.org/mnist.zip -o mnist.zip\n",
    "!mkdir data\n",
    "!unzip mnist.zip -d data/mnist/\n",
    "!rm mnist.zip\n",
    "!gunzip data/mnist -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def load_mnist_data(test=False):\n",
    "    if(test):\n",
    "        f_images = open('data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "        f_labels = open('data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "    else:\n",
    "        f_images = open('data/mnist/train-images-idx3-ubyte', 'rb')\n",
    "        f_labels = open('data/mnist/train-labels-idx1-ubyte', 'rb')\n",
    "\n",
    "    # skip bullshit start\n",
    "    f_images.seek(16)\n",
    "    f_labels.seek(8)\n",
    "\n",
    "    # read whole file\n",
    "    buf_images = f_images.read()\n",
    "    buf_labels = f_labels.read()\n",
    "\n",
    "    images = np.copy(\n",
    "        np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    )\n",
    "    images = images.reshape(-1, 1, 28, 28) / 256\n",
    "\n",
    "    labels = np.copy(\n",
    "        np.frombuffer(buf_labels, dtype=np.uint8)\n",
    "    )\n",
    "    labels_one_hot = np.zeros((labels.shape[0], 10))\n",
    "    labels_one_hot[np.arange(labels.size), labels] = 1\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def sample_batch(X, Y, batch_size=32):\n",
    "    length = len(Y)\n",
    "    idx = np.random.choice(np.arange(0, length),\n",
    "                           size=(batch_size), replace=False)\n",
    "\n",
    "    return X[idx], Y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from perceiver import PerceiverLogits, load_mnist_model\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def set_random_seed(value):\n",
    "    torch.manual_seed(value)\n",
    "    np.random.seed(value)\n",
    "    random.seed(value)\n",
    "\n",
    "\n",
    "set_random_seed(10)\n",
    "\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\"\"\"model = PerceiverLogits(\n",
    "    input_channels=1,\n",
    "    input_shape=(28, 28),\n",
    "    fourier_bands=4,\n",
    "    output_features=10,\n",
    "    latents=8,\n",
    "    d_model=16,\n",
    "    heads=8,\n",
    "    latent_blocks=6,\n",
    "    dropout=0.1,\n",
    "    layers=6\n",
    ")\"\"\"\n",
    "#model = torch.load('./checkpoints/epoch9')\n",
    "\n",
    "\n",
    "def test(model, DEVICE='cpu'):\n",
    "    model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        X_test, Y_test = load_mnist_data(test=True)\n",
    "        X_LENGTH = len(X_test)\n",
    "        BATCH_SIZE = 500\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i in range(X_LENGTH // BATCH_SIZE):\n",
    "            x = torch.from_numpy(\n",
    "                X_test[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "            ).float().to(DEVICE)\n",
    "            y = torch.from_numpy(\n",
    "                Y_test[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "            ).long().to(DEVICE)\n",
    "\n",
    "            y_ = model(x).argmax(dim=-1)\n",
    "\n",
    "            total += len(y_)\n",
    "            correct += (y_ == y).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "\n",
    "\n",
    "def train(model, SKIP_EPOCHS=-1, EPOCHS=24, BATCH_SIZE=32, DEVICE='cpu'):\n",
    "    model.train()\n",
    "    model = model.to(DEVICE)\n",
    "    gamma = 0.1 ** 0.5  # 0.3ish\n",
    "    optimizer = optim.Adam(model.parameters(), lr=gamma * 0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=3, gamma=gamma, last_epoch=-1, verbose=False)\n",
    "\n",
    "    X_train, Y_train = load_mnist_data(test=False)\n",
    "    X_LENGTH = len(X_train)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        if(epoch <= SKIP_EPOCHS):\n",
    "            scheduler.step()\n",
    "            continue\n",
    "        else:\n",
    "            print('EPOCH', epoch, '[LEARNING RATE: ' + str(optimizer.param_groups[0]\n",
    "                                                           ['lr']) + '; ACCURACY: ' + str(test(model, DEVICE=DEVICE)) + ']')\n",
    "\n",
    "        t = trange(X_LENGTH // BATCH_SIZE)\n",
    "        for _ in t:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = sample_batch(X_train, Y_train, BATCH_SIZE)\n",
    "            x = torch.from_numpy(x).float().to(DEVICE)\n",
    "            y = torch.from_numpy(y).long().to(DEVICE)\n",
    "\n",
    "            y_ = model(x)\n",
    "            loss = nn.NLLLoss()(y_, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(str(loss.item())[0:5])\n",
    "        scheduler.step()\n",
    "\n",
    "        if(not os.path.exists('checkpoints')):\n",
    "            os.mkdir('checkpoints')\n",
    "        torch.save(model, 'checkpoints/epoch' + str(epoch))\n",
    "\n",
    "\n",
    "#train(model, SKIP_EPOCHS=-1)\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
